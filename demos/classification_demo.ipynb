{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aubricot/nsm/blob/main/demos/classification_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XuJS_OF3wA8K"
      },
      "source": [
        "#**Squamate Vertebra Classification Demo**   \n",
        "*Last edited 19 Jan 2026*\n",
        "\n",
        "This notebook demonstrates classification of vertebra species and position (modern and fossil) using a trained Neural Shape Model (NSM; Gatti et al. 2025, Park et al. 2019). It can be run fully in demo mode without connecting to your Google Drive. Adjust parameters using form fields and make sure your runtime environment is set to run on GPU. Full repository code is available at [aubricot/nsm on GitHub](https://github.com/aubricot/nsm).\n",
        "\n",
        "Modern vertebra meshes are derived from micro-CT data produced by the oVert Initiative (Blackburn et al. 2024). Fossil vertebra were downloaded from MorphoSource ([UF546657](https://doi.org/10.17602/M2/M600663); [UF271967](https://n2t.net/ark:/87602/m4/M69199)). All vertebrae were aligned and scaled using ATLAS before training (Porto et al. 2026).\n",
        "\n",
        "\n",
        "**References**\n",
        "* Blackburn et al. 2024, BioScience. https://doi.org/10.1093/biosci/biad120\n",
        "* Gatti et al. 2025, IEEE TMI. https://doi.org/10.1109/tmi.2024.3485613\n",
        "* Park et al. 2019, CVPR. https://doi.org/10.48550/arXiv.1901.05103\n",
        "* Porto et al. 2026, in prep. https://github.com/agporto/ATLAS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arE-9o6jwA8L"
      },
      "source": [
        "## 1. Installs & Imports"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Check GPU and CUDA info - make sure Colab Runtime set to GPU\n",
        "from psutil import virtual_memory\n",
        "\n",
        "# Check GPU and CUDA\n",
        "!nvcc --version\n",
        "gpu = !nvidia-smi\n",
        "gpu = '\\n'.join(gpu)\n",
        "print('\\033[91mNot connected to a GPU\\033[0m' if 'failed' in gpu else gpu)\n",
        "\n",
        "# Check RAM\n",
        "ram = virtual_memory().total / 1e9\n",
        "print(f'\\033[92mYour runtime has {ram:.1f} GB of RAM\\033[0m\\n')"
      ],
      "metadata": {
        "id": "IX_Hd2ZXibqe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Choose where to save results\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# Use dropdown menu on right\n",
        "save = \"in Colab runtime (files deleted after each session)\" #@param [\"in my Google Drive\", \"in Colab runtime (files deleted after each session)\"]\n",
        "\n",
        "# Mount google drive to export image tagging file(s)\n",
        "if 'Google Drive' in save:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive', force_remount=False)\n",
        "\n",
        "# Type in the path to your project wd in form field on right\n",
        "base_wd = \"/content/drive/MyDrive\" # @param [\"/content/drive/MyDrive/nsm\"] {\"allow-input\":true}\n",
        "wd = base_wd + \"/nsm\"\n",
        "print(f\"\\033[92mWorking directory set to: \\n{wd}\\033[0m\")"
      ],
      "metadata": {
        "id": "ZP-qynnLiqNA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-AnisFL5wA8M"
      },
      "outputs": [],
      "source": [
        "#@title Set up environment and install NSM\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# Install PyTorch with CUDA support (Colab typically has CUDA 11.8 or 12.x)\n",
        "print(\"\\033[92mSetting up environment...\\033[0m\")\n",
        "print(\"\\n\\033[33m-----This will take a few minutes----\\033[0m\")\n",
        "!pip install torch==2.5.1 torchvision==0.20.1 torchaudio==2.5.1 --index-url https://download.pytorch.org/whl/cu124\n",
        "\n",
        "# Install other dependencies\n",
        "!pip install pyvista mskt open3d scikit-learn matplotlib pandas numpy scipy\n",
        "!pip install ipywidgets\n",
        "!pip install nibabel scikit-image opencv-python open3d\n",
        "\n",
        "# Clone NSM repository\n",
        "if not os.path.exists(wd):\n",
        "    print(\"Cloning NSM repository...\")\n",
        "    os.makedirs(base_wd, exist_ok=True)\n",
        "    %cd $base_wd\n",
        "    !git clone https://github.com/aubricot/nsm.git\n",
        "else:\n",
        "    print(\"NSM directory already exists\")\n",
        "\n",
        "# Navigate to nsm directory and install\n",
        "%cd $wd\n",
        "\n",
        "# Install requirements\n",
        "print(\"\\n-----Installing requirements-----\")\n",
        "!python -m pip install -r requirements.txt\n",
        "\n",
        "# Install NSM package\n",
        "print(\"\\n-----Installing NSM-----\")\n",
        "!pip install .\n",
        "\n",
        "# Add to Python path\n",
        "sys.path.insert(0, wd)\n",
        "%cd $wd\n",
        "print(f\"\\n\\033[92mCurrent working directory set to: {os.getcwd()}\\033[0m\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Import libraries and define functions\n",
        "\n",
        "# For rendering meshes\n",
        "import pyvista as pv\n",
        "pv.start_xvfb() # Enable PyVista for Colab\n",
        "import plotly.graph_objects as go\n",
        "import pymskt.mesh.meshes as meshes\n",
        "import vtk\n",
        "\n",
        "# For working with ML\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from NSM.helper_funcs import load_config, load_model_and_latents\n",
        "from NSM.optimization import get_top_k_pcs\n",
        "from NSM.helper_funcs import NumpyTransform, convert_ply_to_vtk\n",
        "from NSM.optimization import (sample_near_surface,\n",
        "    downsample_partial_pointcloud,\n",
        "    optimize_latent_partial)\n",
        "from NSM.datasets import SDFSamples\n",
        "from NSM.mesh import create_mesh\n",
        "\n",
        "# For working with data\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import json\n",
        "import re\n",
        "from pathlib import Path\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Identify novel meshes from latent space\n",
        "from NSM.models import TriplanarDecoder\n",
        "from NSM.mesh import get_sdfs\n",
        "from NSM.helper_funcs import NumpyTransform, load_config, load_model_and_latents, convert_ply_to_vtk, get_sdfs, fixed_point_coords, safe_load_mesh_scalars, extract_species_prefix, parse_labels_from_filepaths\n",
        "from NSM.optimization import pca_initialize_latent, get_top_k_pcs, find_similar, find_similar_cos, optimize_latent\n",
        "\n",
        "# Plot pyvista mesh interactively using plotly\n",
        "def pv_to_plotly(mesh, color=\"deepskyblue\", opacity=1.0):\n",
        "    mesh = mesh.extract_surface().triangulate()\n",
        "    faces = mesh.faces.reshape(-1, 4)\n",
        "    return go.Mesh3d(x=mesh.points[:, 0], y=mesh.points[:, 1], z=mesh.points[:, 2],\n",
        "                    i=faces[:, 1], j=faces[:, 2], k=faces[:, 3],\n",
        "                    color=color, opacity=opacity, flatshading=False,\n",
        "                    lighting=dict(ambient=0.12, diffuse=0.88, specular=0.05,\n",
        "                                  roughness=0.9, fresnel=0.0),\n",
        "                    lightposition=dict(x=0, y=0, z=2))\n",
        "\n",
        "def plot_predictions(dim_reduced_coords, similar_coords, novel_coord, filepaths, out_fn):\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        plt.scatter(dim_reduced_coords[:, 0], dim_reduced_coords[:, 1], color='gray', alpha=0.3, label='Training Meshes')\n",
        "        # Plot most similar (1st one) in pink\n",
        "        plt.scatter(similar_coords[0, 0], similar_coords[0, 1], color='hotpink', s=80, label='Most Similar')\n",
        "        # Plot next 4 similar in blue\n",
        "        if len(similar_coords) > 1:\n",
        "            plt.scatter(similar_coords[1:, 0], similar_coords[1:, 1], color='blue', s=60, label='Other Top-5 Similar')\n",
        "        # Plot novel mesh in red\n",
        "        plt.scatter(*novel_coord, color='red', s=80, label='Novel Mesh')\n",
        "        # Aannotate each of the top-5 similar meshes\n",
        "        for idx, (x, y) in zip(similar_ids, similar_coords):\n",
        "            plt.text(x, y, filepaths[idx].split('.')[0], fontsize=6, color='black')\n",
        "        plt.title(\"Latent Space Visualization (PCA)\")\n",
        "        plt.xlabel(\"Component 1\")\n",
        "        plt.ylabel(\"Component 2\")\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(outfpath + \"/\" + out_fn, dpi=300)\n",
        "        plt.show()\n",
        "        plt.close()\n",
        "\n",
        "# Monkey patch for data types ----\n",
        "from NSM.helper_funcs import safe_load_mesh_scalars, fixed_point_coords\n",
        "meshes.Mesh.load_mesh_scalars = safe_load_mesh_scalars\n",
        "meshes.Mesh.point_coords = property(fixed_point_coords)\n",
        "\n",
        "import pymskt.mesh.meshTools as meshTools\n",
        "_original_signed_distance_to_mesh = meshTools.pcu.signed_distance_to_mesh\n",
        "def _signed_distance_to_mesh_patch(pts, points, faces):\n",
        "    pts = np.asarray(pts, dtype=np.float64)     # force double precision\n",
        "    points = np.asarray(points, dtype=np.float64)\n",
        "    faces = np.asarray(faces, dtype=np.int32)   # ensure integer type for faces\n",
        "    return _original_signed_distance_to_mesh(pts, points, faces)\n",
        "meshTools.pcu.signed_distance_to_mesh = _signed_distance_to_mesh_patch\n",
        "# End monkey patch ----"
      ],
      "metadata": {
        "id": "Y7teNyyTwCfx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "30csw-ujwA8N"
      },
      "outputs": [],
      "source": [
        "#@title Download models and meshes to appropriate folders\n",
        "\n",
        "# Update these paths to point to your model and data\n",
        "MODEL_DIR = \"run_v44\" # @param [\"run_v44\"] {\"allow-input\":true}\n",
        "!gdown 1hRLyVdtqD2tF6wbE5m1Da0hLtHXiQ_oj\n",
        "!unzip -o {MODEL_DIR}.zip -d {MODEL_DIR} && rm -f {MODEL_DIR}.zip\n",
        "\n",
        "# Checkpoint to use\n",
        "CKPT = \"3000\" # @param [\"3000\"] {\"allow-input\":true}\n",
        "CKPT_fn = CKPT + '.pth'\n",
        "\n",
        "# Fossil directory\n",
        "fossil_dir = \"fossils\" # @param [\"fossils\"] {\"allow-input\":true}\n",
        "#os.makedirs(fossil_dir, exist_ok=True)\n",
        "#%cd $fossil_dir\n",
        "!gdown 1UgKYDj4d5d0D4M8MfHFAh-IkW-dkmujf\n",
        "!unzip -o {fossil_dir}.zip -d {fossil_dir} && rm -f {fossil_dir}.zip\n",
        "\n",
        "# Modern vertebrae directory\n",
        "vertebrae_dir = \"vertebrae_meshes\" # @param [\"vertebrae_meshes\"] {\"allow-input\":true}\n",
        "%cd $wd\n",
        "!rm -rf $vertebrae_dir # Delete demo vertebrae_meshes dir from nsm github\n",
        "!gdown 1EaQJEfryoziFjdfYmI2-UPoF0wvhdnhS\n",
        "!unzip -o {vertebrae_dir}.zip -d {vertebrae_dir} && rm -f {vertebrae_dir}.zip\n",
        "\n",
        "# Output directory\n",
        "OUTPUT_DIR = \"classification\" # @param [\"outputs\"] {\"allow-input\":true}\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "%cd $OUTPUT_DIR\n",
        "!gdown 19V3DlpthWjI_5ttmmxepeY20iI87LB0N\n",
        "OUTPUT_DIR = OUTPUT_DIR + \"/predictions\"\n",
        "%cd $wd\n",
        "!unzip -o {OUTPUT_DIR}.zip -d {OUTPUT_DIR} && rm -f {OUTPUT_DIR}.zip\n",
        "\n",
        "print(f\"\\n\\033[92mSet up working directory and downloaded model and mesh files.\")\n",
        "print(f\"Model directory: {MODEL_DIR}\")\n",
        "print(f\"Checkpoint: {CKPT}\")\n",
        "print(f\"Output directory: {OUTPUT_DIR}\\033[0m\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYEQCEYJwA8P"
      },
      "source": [
        "## 2. Classification\n",
        "\n",
        "Classify the species and spinal position of a novel squamate vertebra mesh (modern or fossil).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1RxqD8QMwA8O"
      },
      "outputs": [],
      "source": [
        "#@title Load model and latent codes\n",
        "\n",
        "# Change to model directory\n",
        "%cd $MODEL_DIR\n",
        "\n",
        "# Load config\n",
        "config = load_config(config_path='model_params_config.json')\n",
        "device = config.get(\"device\", \"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Training dataset mesh names\n",
        "train_paths = config['list_mesh_paths']\n",
        "all_vtk_files = [os.path.basename(f) for f in train_paths]\n",
        "\n",
        "# Paths to model and latent codes\n",
        "LC_PATH = f'latent_codes/{CKPT}.pth'\n",
        "MODEL_PATH = f'model/{CKPT}.pth'\n",
        "\n",
        "# Load model and latents\n",
        "print(\"Loading model and latents...\")\n",
        "model, latent_ckpt, latent_codes = load_model_and_latents(MODEL_PATH, LC_PATH, config, device)\n",
        "\n",
        "# Compute statistics\n",
        "mean_latent = latent_codes.mean(dim=0, keepdim=True)\n",
        "latent_std = latent_codes.std().mean()\n",
        "_, top_k_reg = get_top_k_pcs(latent_codes, threshold=0.99)\n",
        "\n",
        "# Return to original directory\n",
        "%cd $wd\n",
        "\n",
        "print(f\"\\nLatent size: {config['latent_size']}\")\n",
        "print(f\"Number of training samples: {len(latent_codes)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8MEfiLsewA8P",
        "cellView": "code"
      },
      "outputs": [],
      "source": [
        "#@title Load mesh into latent space\n",
        "\n",
        "# Pick a mesh\n",
        "mesh_dir = fossil_dir # @param [\"fossil_dir\",\"vertebrae_dir\"] {\"type\":\"raw\",\"allow-input\":true}\n",
        "mesh_path = random.choice(os.listdir(mesh_dir))\n",
        "print(f\"Mesh being loaded from directory: {mesh_dir}\\n{mesh_path}\\n\")\n",
        "\n",
        "# Setup output directory\n",
        "mesh_name = os.path.splitext(os.path.basename(mesh_path))[0]\n",
        "outfpath = os.path.join(OUTPUT_DIR, mesh_name)\n",
        "os.makedirs(outfpath, exist_ok=True)\n",
        "print(f\"Saving results to output directory: {outfpath}\")\n",
        "\n",
        "# Set up output path for novel mesh\n",
        "output_path = os.path.join(outfpath, f\"{mesh_name}_decoded_novel_pca_regularized_95pct_cos.vtk\")\n",
        "\n",
        "# Convert PLY to VTK if needed\n",
        "mesh_path = os.path.join(mesh_dir, mesh_path)\n",
        "vert_fname = mesh_path\n",
        "if '.ply' in mesh_path.lower():\n",
        "    print(\"Converting PLY to VTK...\")\n",
        "    mesh, vert_fname = convert_ply_to_vtk(mesh_path, save=True)\n",
        "\n",
        "# Setup dataset\n",
        "summary_log = []\n",
        "print(\"\\n-----Setting up dataset-----\")\n",
        "sdf_dataset = SDFSamples(\n",
        "    list_mesh_paths=[vert_fname],\n",
        "    multiprocessing=False,\n",
        "    subsample=config[\"samples_per_object_per_batch\"],\n",
        "    print_filename=True,\n",
        "    n_pts=config[\"n_pts_per_object\"],\n",
        "    p_near_surface=config['percent_near_surface'],\n",
        "    p_further_from_surface=config['percent_further_from_surface'],\n",
        "    sigma_near=config['sigma_near'],\n",
        "    sigma_far=config['sigma_far'],\n",
        "    rand_function=config['random_function'],\n",
        "    center_pts=config['center_pts'],\n",
        "    norm_pts=config['normalize_pts'],\n",
        "    scale_method=config['scale_method'],\n",
        "    reference_mesh=None,\n",
        "    verbose=config['verbose'],\n",
        "    save_cache=config['cache'],\n",
        "    equal_pos_neg=config['equal_pos_neg'],\n",
        "    fix_mesh=config['fix_mesh'])\n",
        "\n",
        "# Get SDF data\n",
        "sdf_sample = sdf_dataset[0]\n",
        "sample_dict, _ = sdf_sample\n",
        "points = sample_dict['xyz'].to(device)\n",
        "sdf_vals = sample_dict['gt_sdf']\n",
        "\n",
        "# Optimize latents (DeepSDF has no encoder, so must use optimization to encode novel data)\n",
        "print(\"\\n-----Optimizing latents-----\")\n",
        "latent_novel = optimize_latent(model, points, sdf_vals, config['latent_size'], top_k_reg, mean_latent, latent_codes)\n",
        "print(\"Translated novel mesh into latent space!\")\n",
        "\n",
        "# Classify vertebra\n",
        "\n",
        "# Find most similar latents (Compare to existing latents)\n",
        "print(\"\\n-----Finding most similar meshes-----\")\n",
        "similar_ids, distances = find_similar_cos(latent_novel, latent_codes, top_k=5, n_std=2, device=device)\n",
        "\n",
        "# Write most similar meshes to txt file\n",
        "sim_mesh_fpath = outfpath + '/' + 'similar_meshes_pca_regularized_95pct_cos.txt'\n",
        "with open(sim_mesh_fpath, \"w\") as f:\n",
        "    print(f\"Most similar mesh indices to file: {os.path.basename(vert_fname)}\\n\")\n",
        "    f.write(f\"Most similar mesh indices to file: {os.path.basename(vert_fname)}:\\n\")\n",
        "    header = \"Name: , Index: , Distance:  \"\n",
        "    f.write(header + \"\\n\")\n",
        "    for i, d in zip(similar_ids, distances):\n",
        "          # Now construct the line using the integer i\n",
        "          line = f\"{all_vtk_files[i]}, {i}, {d:.4f}\"\n",
        "          print(line)\n",
        "          f.write(line + \"\\n\")\n",
        "print(f\"\\n\\033[92mMost similar meshes written to file: {sim_mesh_fpath}\\033[0m\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Inspect novel latent using clustering analysis\n",
        "\n",
        "# PCA Plot\n",
        "# Data loading\n",
        "latents = latent_codes.cpu().numpy()\n",
        "pca = PCA(n_components=2)\n",
        "coords_2d = pca.fit_transform(latents)\n",
        "novel_coord = pca.transform(latent_novel.cpu().numpy())[0]\n",
        "similar_coords = coords_2d[similar_ids]\n",
        "plot_predictions(coords_2d, similar_coords, novel_coord, all_vtk_files, out_fn=\"latent_space_pca_pca_regularized_95pct_cos.png\")\n",
        "print('\\n\\n\\n')\n",
        "\n",
        "# t-SNE Plot\n",
        "# Data loading\n",
        "latent_novel_np = latent_novel.detach().cpu().numpy()\n",
        "latents_with_novel = np.vstack([latents, latent_novel_np])\n",
        "tsne = TSNE(n_components=2, perplexity=30, learning_rate=200, random_state=42)\n",
        "coords_with_novel = tsne.fit_transform(latents_with_novel)\n",
        "train_coords = coords_with_novel[:-1]\n",
        "novel_coord = coords_with_novel[-1]\n",
        "similar_coords = train_coords[similar_ids]\n",
        "plot_predictions(train_coords, similar_coords, novel_coord, all_vtk_files, \"latent_space_tsne_pca_regularized_95pct_cos.png\")"
      ],
      "metadata": {
        "id": "wvTlHkMBZnSo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "du1HbsDjwA8Q"
      },
      "source": [
        "## 3. Inspect Results"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title View the top-5 most similar meshes\n",
        "\n",
        "# Inspect head of summary_matches csv file\n",
        "df = pd.read_csv(sim_mesh_fpath, header=1)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "pF4DMm2CXVEr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Plot the original mesh\n",
        "\n",
        "# Read mesh\n",
        "orig_mesh_name = mesh_name\n",
        "original_mesh = pv.read(os.path.join(mesh_dir, f\"{mesh_name}.vtk\"))\n",
        "original_mesh.compute_normals(inplace=True)\n",
        "\n",
        "# Plot figure\n",
        "fig = go.Figure()\n",
        "trace = pv_to_plotly(original_mesh, 'goldenrod', 1)\n",
        "trace.name = \"Original mesh\"\n",
        "fig.add_trace(trace)\n",
        "for trace in fig.data:\n",
        "    trace.showlegend = True\n",
        "fig.update_layout(title=dict(text=f\"Original Mesh (before completion)<br>{mesh_name}\",\n",
        "                             x=0.5, y=0.95, xanchor=\"center\", yanchor=\"top\"),\n",
        "                  showlegend=True,\n",
        "                  scene_aspectmode='data',\n",
        "                  legend=dict(x=1.02, y=1, bgcolor=\"rgba(255,255,255,0.7)\",\n",
        "                              bordercolor=\"black\", borderwidth=1),\n",
        "                  margin=dict(l=10, r=10, b=10, t=80))\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "ZmQCtgL3Mu0W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Randomly select and plot meshes from the top-5 most similar\n",
        "\n",
        "# Loop through each mesh name in the DataFrame\n",
        "mesh_list = []\n",
        "for mesh_name in df['Name: ']:\n",
        "    # Check if the mesh file exists in the directory\n",
        "    if os.path.isfile(os.path.join(vertebrae_dir, mesh_name)):\n",
        "        # If the file exists, append the mesh name to mesh_list\n",
        "        mesh_list.append(mesh_name)\n",
        "\n",
        "# Print the mesh list with the files that exist in the directory\n",
        "print(\"Meshes found in directory:\", mesh_list)\n",
        "\n",
        "# Read mesh\n",
        "mesh_name = random.choice(mesh_list)\n",
        "top_mesh = pv.read(os.path.join(vertebrae_dir, f\"{mesh_name}\"))\n",
        "print(\"Inspecting randomly chosen similar mesh: \", top_mesh)\n",
        "top_mesh.compute_normals(inplace=True)\n",
        "\n",
        "# Plot figure\n",
        "fig = go.Figure()\n",
        "trace = pv_to_plotly(top_mesh, 'deepskyblue', 1)\n",
        "trace.name = \"Top-5 Similar Mesh\"\n",
        "fig.add_trace(trace)\n",
        "for trace in fig.data:\n",
        "    trace.showlegend = True\n",
        "fig.update_layout(title=dict(text=f\"Top-5 Similar Mesh<br>{mesh_name}\",\n",
        "                             x=0.5, y=0.95, xanchor=\"center\", yanchor=\"top\"),\n",
        "                  showlegend=True,\n",
        "                  scene_aspectmode='data',\n",
        "                  legend=dict(x=1.02, y=1, bgcolor=\"rgba(255,255,255,0.7)\",\n",
        "                              bordercolor=\"black\", borderwidth=1),\n",
        "                  margin=dict(l=10, r=10, b=10, t=80))\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "ZXLFetfnXKcU"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}