{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aubricot/nsm/blob/main/demos/classification_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XuJS_OF3wA8K"
      },
      "source": [
        "#**Squamate Vertebra Classification Demo**   \n",
        "*Last edited 19 Jan 2026*\n",
        "\n",
        "This notebook demonstrates classification of vertebra species and position (modern and fossil) using a trained Neural Shape Model (NSM; Gatti et al. 2025, Park et al. 2019). It can be run fully in demo mode without connecting to your Google Drive. Adjust parameters using form fields and make sure your runtime environment is set to run on GPU. Full repository code is available at [aubricot/nsm on GitHub](https://github.com/aubricot/nsm).\n",
        "\n",
        "Modern vertebra meshes are derived from micro-CT data produced by the oVert Initiative (Blackburn et al. 2024). Fossil vertebra were downloaded from MorphoSource ([UF546657](https://doi.org/10.17602/M2/M600663); [UF271967](https://n2t.net/ark:/87602/m4/M69199)). All vertebrae were aligned and scaled using ATLAS before training (Porto et al. 2026).\n",
        "\n",
        "\n",
        "**References**\n",
        "* Blackburn et al. 2024, BioScience. https://doi.org/10.1093/biosci/biad120\n",
        "* Gatti et al. 2025, IEEE TMI. https://doi.org/10.1109/tmi.2024.3485613\n",
        "* Park et al. 2019, CVPR. https://doi.org/10.48550/arXiv.1901.05103\n",
        "* Porto et al. 2026, in prep. https://github.com/agporto/ATLAS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arE-9o6jwA8L"
      },
      "source": [
        "# 1. Installs & Imports\n",
        "---\n",
        "This notebook can run fully in the cloud or can be connected to your Google Drive to save results. Run these code blocks to set up your environment before proceeding with classification."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Check that your Colab runtime environment is set to use GPU.\n",
        "Go to the top right corner of this notebook → Click the arrow → Change runtime type  → Hardware Accelerator  → any option with GPU"
      ],
      "metadata": {
        "id": "oUA6xqY2X2ix"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check GPU and CUDA info - make sure Colab Runtime set to GPU\n",
        "from psutil import virtual_memory\n",
        "\n",
        "# Check GPU and CUDA\n",
        "!nvcc --version\n",
        "gpu = !nvidia-smi\n",
        "gpu = '\\n'.join(gpu)\n",
        "print('\\033[91mNot connected to a GPU\\033[0m' if 'failed' in gpu else gpu)\n",
        "\n",
        "# Check RAM\n",
        "ram = virtual_memory().total / 1e9\n",
        "print(f'\\033[92mYour runtime has {ram:.1f} GB of RAM\\033[0m\\n')"
      ],
      "metadata": {
        "id": "IX_Hd2ZXibqe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Choose where to save results\n",
        "This notebook can be run fully within the Colab runtime environment (files are deleted after each session) or it can be connected to your Google Drive. To customize, run the form fields on the right to set the parameters for \"save\" and \"base_wd\" to determine your base working directory where files will go."
      ],
      "metadata": {
        "id": "gTD-WS91YABn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose where to save results\n",
        "\n",
        "# Use dropdown menu on right\n",
        "save = \"in Colab runtime (files deleted after each session)\" #@param [\"in my Google Drive\", \"in Colab runtime (files deleted after each session)\"]\n",
        "\n",
        "# Mount google drive to export image tagging file(s)\n",
        "if 'Google Drive' in save:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive', force_remount=False)\n",
        "\n",
        "# Type in the path to your project wd in form field on right\n",
        "base_wd = \"/content/drive/MyDrive\" # @param [\"/content/drive/MyDrive/nsm\"] {\"allow-input\":true}\n",
        "wd = base_wd + \"/nsm\"\n",
        "print(f\"\\033[92mWorking directory set to: \\n{wd}\\033[0m\")"
      ],
      "metadata": {
        "id": "ZP-qynnLiqNA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set up environment and install NSM\n",
        "Machine learning environments have specific versions required for certain libaries. The code below first ensures that all the versions installed are compatible with NSM. Then, it clones NSM from GitHub, installs other required packages, and installs NSM."
      ],
      "metadata": {
        "id": "NU-_7JbJYJMo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-AnisFL5wA8M"
      },
      "outputs": [],
      "source": [
        "# Set up environment and install NSM\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# Install PyTorch with CUDA support (Colab typically has CUDA 11.8 or 12.x)\n",
        "print(\"\\033[92mSetting up environment...\\033[0m\")\n",
        "print(\"\\n\\033[33m-----This will take a few minutes----\\033[0m\")\n",
        "!pip install torch==2.5.1 torchvision==0.20.1 torchaudio==2.5.1 --index-url https://download.pytorch.org/whl/cu124\n",
        "\n",
        "# Install other dependencies\n",
        "!pip install pyvista mskt open3d scikit-learn matplotlib pandas numpy scipy\n",
        "!pip install ipywidgets\n",
        "!pip install nibabel scikit-image opencv-python open3d\n",
        "\n",
        "# Clone NSM repository\n",
        "if not os.path.exists(wd):\n",
        "    print(\"Cloning NSM repository...\")\n",
        "    os.makedirs(base_wd, exist_ok=True)\n",
        "    %cd $base_wd\n",
        "    !git clone https://github.com/aubricot/nsm.git\n",
        "else:\n",
        "    print(\"NSM directory already exists\")\n",
        "\n",
        "# Navigate to nsm directory and install\n",
        "%cd $wd\n",
        "\n",
        "# Install requirements\n",
        "print(\"\\n-----Installing requirements-----\")\n",
        "!python -m pip install -r requirements.txt\n",
        "\n",
        "# Install NSM package\n",
        "print(\"\\n-----Installing NSM-----\")\n",
        "!pip install .\n",
        "\n",
        "# Add to Python path\n",
        "sys.path.insert(0, wd)\n",
        "%cd $wd\n",
        "print(f\"\\n\\033[92mCurrent working directory set to: {os.getcwd()}\\033[0m\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import libraries and define functions\n",
        "Import required libraries and define functions to be used downstream"
      ],
      "metadata": {
        "id": "603F7pBJYUu0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries and define functions\n",
        "\n",
        "# For rendering meshes\n",
        "import pyvista as pv\n",
        "pv.start_xvfb() # Enable PyVista for Colab\n",
        "import plotly.graph_objects as go\n",
        "import pymskt.mesh.meshes as meshes\n",
        "import vtk\n",
        "\n",
        "# For working with ML\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from NSM.helper_funcs import load_config, load_model_and_latents\n",
        "from NSM.optimization import get_top_k_pcs\n",
        "from NSM.helper_funcs import NumpyTransform, convert_ply_to_vtk\n",
        "from NSM.optimization import (sample_near_surface,\n",
        "    downsample_partial_pointcloud,\n",
        "    optimize_latent_partial)\n",
        "from NSM.datasets import SDFSamples\n",
        "from NSM.mesh import create_mesh\n",
        "\n",
        "# For working with data\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import json\n",
        "import re\n",
        "from pathlib import Path\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Identify novel meshes from latent space\n",
        "from NSM.models import TriplanarDecoder\n",
        "from NSM.mesh import get_sdfs\n",
        "from NSM.helper_funcs import NumpyTransform, load_config, load_model_and_latents, convert_ply_to_vtk, get_sdfs, fixed_point_coords, safe_load_mesh_scalars, extract_species_prefix, parse_labels_from_filepaths\n",
        "from NSM.optimization import pca_initialize_latent, get_top_k_pcs, find_similar, find_similar_cos, optimize_latent\n",
        "\n",
        "# Plot pyvista mesh interactively using plotly\n",
        "def pv_to_plotly(mesh, color=\"deepskyblue\", opacity=1.0):\n",
        "    mesh = mesh.extract_surface().triangulate()\n",
        "    faces = mesh.faces.reshape(-1, 4)\n",
        "    return go.Mesh3d(x=mesh.points[:, 0], y=mesh.points[:, 1], z=mesh.points[:, 2],\n",
        "                    i=faces[:, 1], j=faces[:, 2], k=faces[:, 3],\n",
        "                    color=color, opacity=opacity, flatshading=False,\n",
        "                    lighting=dict(ambient=0.12, diffuse=0.88, specular=0.05,\n",
        "                                  roughness=0.9, fresnel=0.0),\n",
        "                    lightposition=dict(x=0, y=0, z=2))\n",
        "\n",
        "def plot_predictions(dim_reduced_coords, similar_coords, novel_coord, filepaths, out_fn):\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        plt.scatter(dim_reduced_coords[:, 0], dim_reduced_coords[:, 1], color='gray', alpha=0.3, label='Training Meshes')\n",
        "        # Plot most similar (1st one) in pink\n",
        "        plt.scatter(similar_coords[0, 0], similar_coords[0, 1], color='hotpink', s=80, label='Most Similar')\n",
        "        # Plot next 4 similar in blue\n",
        "        if len(similar_coords) > 1:\n",
        "            plt.scatter(similar_coords[1:, 0], similar_coords[1:, 1], color='blue', s=60, label='Other Top-5 Similar')\n",
        "        # Plot novel mesh in red\n",
        "        plt.scatter(*novel_coord, color='red', s=80, label='Novel Mesh')\n",
        "        # Aannotate each of the top-5 similar meshes\n",
        "        for idx, (x, y) in zip(similar_ids, similar_coords):\n",
        "            plt.text(x, y, filepaths[idx].split('.')[0], fontsize=6, color='black')\n",
        "        plt.title(\"Latent Space Visualization (PCA)\")\n",
        "        plt.xlabel(\"Component 1\")\n",
        "        plt.ylabel(\"Component 2\")\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(outfpath + \"/\" + out_fn, dpi=300)\n",
        "        plt.show()\n",
        "        plt.close()\n",
        "\n",
        "# Monkey patch for data types ----\n",
        "from NSM.helper_funcs import safe_load_mesh_scalars, fixed_point_coords\n",
        "meshes.Mesh.load_mesh_scalars = safe_load_mesh_scalars\n",
        "meshes.Mesh.point_coords = property(fixed_point_coords)\n",
        "\n",
        "import pymskt.mesh.meshTools as meshTools\n",
        "_original_signed_distance_to_mesh = meshTools.pcu.signed_distance_to_mesh\n",
        "def _signed_distance_to_mesh_patch(pts, points, faces):\n",
        "    pts = np.asarray(pts, dtype=np.float64)     # force double precision\n",
        "    points = np.asarray(points, dtype=np.float64)\n",
        "    faces = np.asarray(faces, dtype=np.int32)   # ensure integer type for faces\n",
        "    return _original_signed_distance_to_mesh(pts, points, faces)\n",
        "meshTools.pcu.signed_distance_to_mesh = _signed_distance_to_mesh_patch\n",
        "# End monkey patch ----"
      ],
      "metadata": {
        "id": "Y7teNyyTwCfx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Load in models and data\n",
        "---\n",
        "Load models and data to do demo shape completion in your Colab runtime environment."
      ],
      "metadata": {
        "id": "YdW7nBWLYv4T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download models and meshes to appropriate folders\n",
        "Use gdown syntax to download demo model and data files to their respective directories. To customize, adjust paths using form fields on right."
      ],
      "metadata": {
        "id": "0YYO6gwDYy8T"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "30csw-ujwA8N"
      },
      "outputs": [],
      "source": [
        "# Download models and meshes to appropriate folders\n",
        "\n",
        "# Update these paths to point to your model and data\n",
        "MODEL_DIR = \"run_v44\" # @param [\"run_v44\"] {\"allow-input\":true}\n",
        "!gdown 1hRLyVdtqD2tF6wbE5m1Da0hLtHXiQ_oj\n",
        "!unzip -o {MODEL_DIR}.zip -d {MODEL_DIR} && rm -f {MODEL_DIR}.zip\n",
        "\n",
        "# Checkpoint to use\n",
        "CKPT = \"3000\" # @param [\"3000\"] {\"allow-input\":true}\n",
        "CKPT_fn = CKPT + '.pth'\n",
        "\n",
        "# Fossil directory\n",
        "fossil_dir = \"fossils\" # @param [\"fossils\"] {\"allow-input\":true}\n",
        "#os.makedirs(fossil_dir, exist_ok=True)\n",
        "#%cd $fossil_dir\n",
        "!gdown 1UgKYDj4d5d0D4M8MfHFAh-IkW-dkmujf\n",
        "!unzip -o {fossil_dir}.zip -d {fossil_dir} && rm -f {fossil_dir}.zip\n",
        "\n",
        "# Modern vertebrae directory\n",
        "vertebrae_dir = \"vertebrae_meshes\" # @param [\"vertebrae_meshes\"] {\"allow-input\":true}\n",
        "%cd $wd\n",
        "!rm -rf $vertebrae_dir # Delete demo vertebrae_meshes dir from nsm github\n",
        "!gdown 1EaQJEfryoziFjdfYmI2-UPoF0wvhdnhS\n",
        "!unzip -o {vertebrae_dir}.zip -d {vertebrae_dir} && rm -f {vertebrae_dir}.zip\n",
        "\n",
        "# Output directory\n",
        "OUTPUT_DIR = \"classification\" # @param [\"outputs\"] {\"allow-input\":true}\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "%cd $OUTPUT_DIR\n",
        "!gdown 19V3DlpthWjI_5ttmmxepeY20iI87LB0N\n",
        "OUTPUT_DIR = OUTPUT_DIR + \"/predictions\"\n",
        "%cd $wd\n",
        "!unzip -o {OUTPUT_DIR}.zip -d {OUTPUT_DIR} && rm -f {OUTPUT_DIR}.zip\n",
        "\n",
        "print(f\"\\n\\033[92mSet up working directory and downloaded model and mesh files.\")\n",
        "print(f\"Model directory: {MODEL_DIR}\")\n",
        "print(f\"Checkpoint: {CKPT}\")\n",
        "print(f\"Output directory: {OUTPUT_DIR}\\033[0m\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYEQCEYJwA8P"
      },
      "source": [
        "## 3. Prepare models and data for inference\n",
        "---\n",
        "Prepare models and data to run inference (classify the species and spinal position of a novel squamate vertebra mesh (modern or fossil)).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load model and latent codes\n",
        "Load files that were downloaded in **2. Load models and data**."
      ],
      "metadata": {
        "id": "gkn4ohmBY_wK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1RxqD8QMwA8O"
      },
      "outputs": [],
      "source": [
        "# Load model and latent codes\n",
        "\n",
        "# Change to model directory\n",
        "%cd $MODEL_DIR\n",
        "\n",
        "# Load config\n",
        "config = load_config(config_path='model_params_config.json')\n",
        "device = config.get(\"device\", \"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Training dataset mesh names\n",
        "train_paths = config['list_mesh_paths']\n",
        "all_vtk_files = [os.path.basename(f) for f in train_paths]\n",
        "\n",
        "# Paths to model and latent codes\n",
        "LC_PATH = f'latent_codes/{CKPT}.pth'\n",
        "MODEL_PATH = f'model/{CKPT}.pth'\n",
        "\n",
        "# Load model and latents\n",
        "print(\"Loading model and latents...\")\n",
        "model, latent_ckpt, latent_codes = load_model_and_latents(MODEL_PATH, LC_PATH, config, device)\n",
        "\n",
        "# Compute statistics\n",
        "mean_latent = latent_codes.mean(dim=0, keepdim=True)\n",
        "latent_std = latent_codes.std().mean()\n",
        "_, top_k_reg = get_top_k_pcs(latent_codes, threshold=0.99)\n",
        "\n",
        "# Return to original directory\n",
        "%cd $wd\n",
        "\n",
        "print(f\"\\nLatent size: {config['latent_size']}\")\n",
        "print(f\"Number of training samples: {len(latent_codes)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load mesh into latent space\n",
        "Pick whether to load a modern (vertebrae_dir) or fossil (fossil_dir) vertebrae from the demo directories, then randomly select a file from the directory for inference."
      ],
      "metadata": {
        "id": "autYOcdOZDrs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8MEfiLsewA8P"
      },
      "outputs": [],
      "source": [
        "# Load mesh into latent space\n",
        "\n",
        "# Pick a mesh\n",
        "mesh_dir = fossil_dir # @param [\"fossil_dir\",\"vertebrae_dir\"] {\"type\":\"raw\",\"allow-input\":true}\n",
        "if not 'fossil' in mesh_dir:\n",
        "    mesh_path = random.choice(os.listdir(mesh_dir))\n",
        "else:\n",
        "    mesh_path = \"zzzzz_fossil_uf546657_fillholes_smooth_shape_completion.vtk\" # @param [\"UF271967.vtk\",\"uf546657.ply\",\"uf546657_shape_completion.vtk\",\"zzzzz_fossil_uf546657_fillholes_smooth_shape_completion.vtk\",\"zzzzz_fossil_uf546657_shape_completion.vtk\"] {\"allow-input\":true}\n",
        "print(f\"Mesh being loaded from directory: {mesh_dir}\\n{mesh_path}\\n\")\n",
        "\n",
        "# Setup output directory\n",
        "mesh_name = os.path.splitext(os.path.basename(mesh_path))[0]\n",
        "outfpath = os.path.join(OUTPUT_DIR, mesh_name)\n",
        "os.makedirs(outfpath, exist_ok=True)\n",
        "print(f\"Saving results to output directory: {outfpath}\")\n",
        "\n",
        "# Set up output path for novel mesh\n",
        "output_path = os.path.join(outfpath, f\"{mesh_name}_decoded_novel_pca_regularized_95pct_cos.vtk\")\n",
        "\n",
        "# Convert PLY to VTK if needed\n",
        "mesh_path = os.path.join(mesh_dir, mesh_path)\n",
        "vert_fname = mesh_path\n",
        "if '.ply' in mesh_path.lower():\n",
        "    print(\"Converting PLY to VTK...\")\n",
        "    mesh, vert_fname = convert_ply_to_vtk(mesh_path, save=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set up the SDF dataset\n",
        "Load mesh into the trained model using SDFSamples() using the same preprocessing that was used during model training (parameters are retrieved from the model config file)."
      ],
      "metadata": {
        "id": "DWpvqhOWZWbA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up the SDF dataset\n",
        "\n",
        "# Setup dataset\n",
        "summary_log = []\n",
        "print(\"\\n-----Setting up dataset-----\")\n",
        "sdf_dataset = SDFSamples(\n",
        "    list_mesh_paths=[vert_fname],\n",
        "    multiprocessing=False,\n",
        "    subsample=config[\"samples_per_object_per_batch\"],\n",
        "    print_filename=True,\n",
        "    n_pts=config[\"n_pts_per_object\"],\n",
        "    p_near_surface=config['percent_near_surface'],\n",
        "    p_further_from_surface=config['percent_further_from_surface'],\n",
        "    sigma_near=config['sigma_near'],\n",
        "    sigma_far=config['sigma_far'],\n",
        "    rand_function=config['random_function'],\n",
        "    center_pts=config['center_pts'],\n",
        "    norm_pts=config['normalize_pts'],\n",
        "    scale_method=config['scale_method'],\n",
        "    reference_mesh=None,\n",
        "    verbose=config['verbose'],\n",
        "    save_cache=config['cache'],\n",
        "    equal_pos_neg=config['equal_pos_neg'],\n",
        "    fix_mesh=config['fix_mesh'])"
      ],
      "metadata": {
        "id": "hpFb4GSyZN4N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Classification\n",
        "---\n",
        "Optimize novel latent and find its top-5 closest matches for species and spinal position."
      ],
      "metadata": {
        "id": "OXb9KIuLaXMb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optimize latents\n",
        "Since NSM is an auto-decoder framework, novel data cannot be encoded into the model the exact same was as training data. To encode new data into the model's latent space, optimization is required, which is similar to a mini training session. After several tests using chamfer distance on our training and test data as ground truths, we determined a 2 phase optimization technique with the defined parameters. Every fossil and dataset are different, and they can be adjusted to fit your use case."
      ],
      "metadata": {
        "id": "yIJJlpXIZ7Kw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get SDF data\n",
        "sdf_sample = sdf_dataset[0]\n",
        "sample_dict, _ = sdf_sample\n",
        "points = sample_dict['xyz'].to(device)\n",
        "sdf_vals = sample_dict['gt_sdf']\n",
        "\n",
        "# Optimize latents (DeepSDF has no encoder, so must use optimization to encode novel data)\n",
        "print(\"\\n-----Optimizing latents-----\")\n",
        "print(\"\\n\\033[33m-----This will take a few minutes----\\033[0m\")\n",
        "latent_novel = optimize_latent(model, points, sdf_vals, config['latent_size'], top_k_reg, mean_latent, latent_codes)\n",
        "print(\"\\n\\033[92mLatent optimization complete\\033[0m\")"
      ],
      "metadata": {
        "id": "lUZA-_CTZ9Pv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classify mesh using optimized latent\n",
        "Feed optimized latent into trained model and determine its closest match for species and spinal position."
      ],
      "metadata": {
        "id": "Lt5vSt3kaBao"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Classify vertebra\n",
        "\n",
        "# Find most similar latents (Compare to existing latents)\n",
        "print(\"\\n-----Finding most similar meshes-----\")\n",
        "similar_ids, distances = find_similar_cos(latent_novel, latent_codes, top_k=5, n_std=2, device=device)\n",
        "\n",
        "# Write most similar meshes to txt file\n",
        "sim_mesh_fpath = outfpath + '/' + 'similar_meshes_pca_regularized_95pct_cos.txt'\n",
        "with open(sim_mesh_fpath, \"w\") as f:\n",
        "    print(f\"Most similar mesh indices to file: {os.path.basename(vert_fname)}\\n\")\n",
        "    f.write(f\"Most similar mesh indices to file: {os.path.basename(vert_fname)}:\\n\")\n",
        "    header = \"Name, Index, Distance\"\n",
        "    f.write(header + \"\\n\")\n",
        "    for i, d in zip(similar_ids, distances):\n",
        "          # Now construct the line using the integer i\n",
        "          line = f\"{all_vtk_files[i]}, {i}, {d:.4f}\"\n",
        "          print(line)\n",
        "          f.write(line + \"\\n\")\n",
        "print(f\"\\n\\033[92mMost similar meshes written to file: {sim_mesh_fpath}\\033[0m\")"
      ],
      "metadata": {
        "id": "VasrvJ0NZUEh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inspect closest points in latent space using PCA and tSNE"
      ],
      "metadata": {
        "id": "WUbbvtgTaM8_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Inspect novel latent using clustering analysis\n",
        "\n",
        "# PCA Plot\n",
        "# Data loading\n",
        "latents = latent_codes.cpu().numpy()\n",
        "pca = PCA(n_components=2)\n",
        "coords_2d = pca.fit_transform(latents)\n",
        "novel_coord = pca.transform(latent_novel.cpu().numpy())[0]\n",
        "similar_coords = coords_2d[similar_ids]\n",
        "plot_predictions(coords_2d, similar_coords, novel_coord, all_vtk_files, out_fn=\"latent_space_pca_pca_regularized_95pct_cos.png\")\n",
        "print('\\n\\n\\n')\n",
        "\n",
        "# t-SNE Plot\n",
        "# Data loading\n",
        "latent_novel_np = latent_novel.detach().cpu().numpy()\n",
        "latents_with_novel = np.vstack([latents, latent_novel_np])\n",
        "tsne = TSNE(n_components=2, perplexity=30, learning_rate=200, random_state=42)\n",
        "coords_with_novel = tsne.fit_transform(latents_with_novel)\n",
        "train_coords = coords_with_novel[:-1]\n",
        "novel_coord = coords_with_novel[-1]\n",
        "similar_coords = train_coords[similar_ids]\n",
        "plot_predictions(train_coords, similar_coords, novel_coord, all_vtk_files, \"latent_space_tsne_pca_regularized_95pct_cos.png\")"
      ],
      "metadata": {
        "id": "wvTlHkMBZnSo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "du1HbsDjwA8Q"
      },
      "source": [
        "# 5. Inspect Results\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title View the top-5 most similar meshes\n",
        "\n",
        "# Inspect head of summary_matches csv file\n",
        "df = pd.read_csv(sim_mesh_fpath, header=1)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "pF4DMm2CXVEr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Plot the original mesh\n",
        "\n",
        "# Read mesh\n",
        "orig_mesh_name = mesh_name\n",
        "original_mesh = pv.read(os.path.join(mesh_dir, f\"{mesh_name}.vtk\"))\n",
        "original_mesh.compute_normals(inplace=True)\n",
        "\n",
        "# Plot figure\n",
        "fig = go.Figure()\n",
        "trace = pv_to_plotly(original_mesh, 'goldenrod', 1)\n",
        "trace.name = \"Original mesh\"\n",
        "fig.add_trace(trace)\n",
        "for trace in fig.data:\n",
        "    trace.showlegend = True\n",
        "fig.update_layout(title=dict(text=f\"Original Mesh<br>{mesh_name}\",\n",
        "                             x=0.5, y=0.95, xanchor=\"center\", yanchor=\"top\"),\n",
        "                  showlegend=True,\n",
        "                  scene_aspectmode='data',\n",
        "                  legend=dict(x=1.02, y=1, bgcolor=\"rgba(255,255,255,0.7)\",\n",
        "                              bordercolor=\"black\", borderwidth=1),\n",
        "                  margin=dict(l=10, r=10, b=10, t=80))\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "ZmQCtgL3Mu0W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Randomly select and plot meshes from the top-5 most similar\n",
        "\n",
        "# Loop through each mesh name in the DataFrame\n",
        "mesh_list = []\n",
        "for mesh_name in df['Name']:\n",
        "    # Check if the mesh file exists in the directory\n",
        "    if os.path.isfile(os.path.join(vertebrae_dir, mesh_name)):\n",
        "        # If the file exists, append the mesh name to mesh_list\n",
        "        mesh_list.append(mesh_name)\n",
        "\n",
        "# Print the mesh list with the files that exist in the directory\n",
        "print(f\"Found {len(mesh_list)} meshes matching Top-5 predictions in directory: {vertebrae_dir}\\n{mesh_list}\\n\")\n",
        "\n",
        "# Read mesh\n",
        "top_mesh_name = random.choice(mesh_list)\n",
        "top_mesh = pv.read(os.path.join(vertebrae_dir, f\"{top_mesh_name}\"))\n",
        "print(\"Inspecting randomly chosen similar mesh: \", top_mesh)\n",
        "top_mesh.compute_normals(inplace=True)\n",
        "\n",
        "# Plot figure\n",
        "fig = go.Figure()\n",
        "trace = pv_to_plotly(top_mesh, 'deepskyblue', 1)\n",
        "trace.name = \"Top-5 Similar Mesh\"\n",
        "fig.add_trace(trace)\n",
        "for trace in fig.data:\n",
        "    trace.showlegend = True\n",
        "fig.update_layout(title=dict(text=f\"Top-5 Similar Mesh<br>{mesh_name}\",\n",
        "                             x=0.5, y=0.95, xanchor=\"center\", yanchor=\"top\"),\n",
        "                  showlegend=True,\n",
        "                  scene_aspectmode='data',\n",
        "                  legend=dict(x=1.02, y=1, bgcolor=\"rgba(255,255,255,0.7)\",\n",
        "                              bordercolor=\"black\", borderwidth=1),\n",
        "                  margin=dict(l=10, r=10, b=10, t=80))\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "ZXLFetfnXKcU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Optional: Save a spinning gif of your 3D models\n",
        "---"
      ],
      "metadata": {
        "id": "3Vc80krmbBNA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Colab + PyVista setup ---\n",
        "from google.colab import files\n",
        "\n",
        "# --- Read mesh\n",
        "mesh_type = \"predicted_match\" # @param [\"original\",\"predicted_match\"] {\"allow-input\":true}\n",
        "if mesh_type == \"predicted_match\":\n",
        "    mesh = top_mesh\n",
        "    mesh_name = top_mesh_name\n",
        "else:\n",
        "    mesh = original_mesh\n",
        "\n",
        "# --- Create plotter ---\n",
        "plotter = pv.Plotter(off_screen=True, window_size=(800, 800))\n",
        "plotter.set_background(\"white\")\n",
        "plotter.add_mesh(mesh, color=\"deepskyblue\", opacity=1.0)\n",
        "\n",
        "# --- Open GIF ---\n",
        "gif_path = f\"{mesh_name}_{mesh_type}_spin.gif\"\n",
        "plotter.open_gif(gif_path, fps=20)\n",
        "\n",
        "# Camera setup\n",
        "plotter.camera.zoom(1.2)\n",
        "\n",
        "# --- Rotate + write frames ---\n",
        "n_frames = 120 # @param {\"type\":\"slider\",\"min\":120,\"max\":360,\"step\":120}\n",
        "for _ in range(n_frames):\n",
        "    plotter.camera.Azimuth(360 / n_frames)\n",
        "    plotter.write_frame()\n",
        "plotter.close()\n",
        "\n",
        "print(f\"Saved GIF to {gif_path}\")\n",
        "\n",
        "# --- Download ---\n",
        "files.download(gif_path)"
      ],
      "metadata": {
        "id": "bVlh62NNbHfo"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}